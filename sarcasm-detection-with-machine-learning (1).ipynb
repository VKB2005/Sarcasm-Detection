{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11657502,"sourceType":"datasetVersion","datasetId":7315615}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Libraries to Import**","metadata":{}},{"cell_type":"markdown","source":"Sarcasm detection is a natural language processing and binary classification task. We can train a machine learning model to detect whether or not a sentence is sarcastic using a dataset of sarcastic and non-sarcastic sentences that I found on Kaggle.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import BernoulliNB","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-03T05:54:00.503396Z","iopub.execute_input":"2025-05-03T05:54:00.503676Z","iopub.status.idle":"2025-05-03T05:54:01.353531Z","shell.execute_reply.started":"2025-05-03T05:54:00.503652Z","shell.execute_reply":"2025-05-03T05:54:01.352698Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"**Dataset Preparation**","metadata":{}},{"cell_type":"code","source":"data = pd.read_json(\"/kaggle/input/data-sarcasam/sarcasam.json\", lines=True)\nprint(data.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T05:56:50.907769Z","iopub.execute_input":"2025-05-03T05:56:50.908447Z","iopub.status.idle":"2025-05-03T05:56:51.102121Z","shell.execute_reply.started":"2025-05-03T05:56:50.908419Z","shell.execute_reply":"2025-05-03T05:56:51.101368Z"}},"outputs":[{"name":"stdout","text":"                                        article_link  \\\n0  https://www.huffingtonpost.com/entry/versace-b...   \n1  https://www.huffingtonpost.com/entry/roseanne-...   \n2  https://local.theonion.com/mom-starting-to-fea...   \n3  https://politics.theonion.com/boehner-just-wan...   \n4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n\n                                            headline  is_sarcastic  \n0  former versace store clerk sues over secret 'b...             0  \n1  the 'roseanne' revival catches up to our thorn...             0  \n2  mom starting to fear son's web series closest ...             1  \n3  boehner just wants wife to listen, not come up...             1  \n4  j.k. rowling wishes snape happy birthday in th...             0  \n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"\nThe “is_sarcastic” column in this dataset contains the labels that we have to predict for the task of sarcasm detection. It contains binary values as 1 and 0, where 1 means sarcastic and 0 means not sarcastic. So for simplicity, I will transform the values of this column as “sarcastic” and “not sarcastic” instead of 1 and 0:","metadata":{}},{"cell_type":"code","source":"data[\"is_sarcastic\"] = data[\"is_sarcastic\"].map({0: \"Not Sarcasm\", 1: \"Sarcasm\"})\nprint(data.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T05:58:41.756202Z","iopub.execute_input":"2025-05-03T05:58:41.756999Z","iopub.status.idle":"2025-05-03T05:58:41.769297Z","shell.execute_reply.started":"2025-05-03T05:58:41.756964Z","shell.execute_reply":"2025-05-03T05:58:41.768552Z"}},"outputs":[{"name":"stdout","text":"                                        article_link  \\\n0  https://www.huffingtonpost.com/entry/versace-b...   \n1  https://www.huffingtonpost.com/entry/roseanne-...   \n2  https://local.theonion.com/mom-starting-to-fea...   \n3  https://politics.theonion.com/boehner-just-wan...   \n4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n\n                                            headline is_sarcastic  \n0  former versace store clerk sues over secret 'b...  Not Sarcasm  \n1  the 'roseanne' revival catches up to our thorn...  Not Sarcasm  \n2  mom starting to fear son's web series closest ...      Sarcasm  \n3  boehner just wants wife to listen, not come up...      Sarcasm  \n4  j.k. rowling wishes snape happy birthday in th...  Not Sarcasm  \n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"data.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T06:00:30.529255Z","iopub.execute_input":"2025-05-03T06:00:30.529614Z","iopub.status.idle":"2025-05-03T06:00:30.535346Z","shell.execute_reply.started":"2025-05-03T06:00:30.529590Z","shell.execute_reply":"2025-05-03T06:00:30.534510Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(26709, 3)"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"Now let’s prepare the data for training a machine learning model. This dataset has three columns, out of which we only need the “headline” column as a feature and the “is_sarcastic” column as a label. So let’s select these columns and split the data into 20% test set and 80% training set:","metadata":{}},{"cell_type":"code","source":"data = data[[\"headline\", \"is_sarcastic\"]] # i am taking only the 2 colums except article_link column\nx = np.array(data[\"headline\"])\ny = np.array(data[\"is_sarcastic\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T06:01:23.387869Z","iopub.execute_input":"2025-05-03T06:01:23.388467Z","iopub.status.idle":"2025-05-03T06:01:23.398696Z","shell.execute_reply.started":"2025-05-03T06:01:23.388444Z","shell.execute_reply":"2025-05-03T06:01:23.397956Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"cv = CountVectorizer()\nX = cv.fit_transform(x) # Fit the Data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T06:01:38.036452Z","iopub.execute_input":"2025-05-03T06:01:38.036747Z","iopub.status.idle":"2025-05-03T06:01:38.294943Z","shell.execute_reply.started":"2025-05-03T06:01:38.036724Z","shell.execute_reply":"2025-05-03T06:01:38.294407Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"Now i am using the bernoulli navie bayes algorithm to train thr model","metadata":{}},{"cell_type":"code","source":"model = BernoulliNB()\nmodel.fit(X_train, y_train)\nprint(model.score(X_test, y_test))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T06:05:25.741220Z","iopub.execute_input":"2025-05-03T06:05:25.741524Z","iopub.status.idle":"2025-05-03T06:05:25.825749Z","shell.execute_reply.started":"2025-05-03T06:05:25.741503Z","shell.execute_reply":"2025-05-03T06:05:25.825151Z"}},"outputs":[{"name":"stdout","text":"0.8448146761512542\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"\nNow let’s use a sarcastic text as input to test whether our machine learning model detects sarcasm or not:","metadata":{}},{"cell_type":"code","source":"user = input(\"Enter a Text: \")\ndata = cv.transform([user]).toarray()\noutput = model.predict(data)\nprint(output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T06:06:15.006135Z","iopub.execute_input":"2025-05-03T06:06:15.006770Z","iopub.status.idle":"2025-05-03T06:06:35.818154Z","shell.execute_reply.started":"2025-05-03T06:06:15.006743Z","shell.execute_reply":"2025-05-03T06:06:35.817416Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"Enter a Text:  Cows lose their jobs as milk prices drop\n"},{"name":"stdout","text":"['Sarcasm']\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"**NOW WE TRY TO INCREASE THE ACCURACY OF MODEL**","metadata":{}},{"cell_type":"markdown","source":"1. Using the TF-IDF instead of Count Vectorizer","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfidf = TfidfVectorizer()\nX = tfidf.fit_transform(x)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T06:25:39.926164Z","iopub.execute_input":"2025-05-03T06:25:39.926867Z","iopub.status.idle":"2025-05-03T06:25:40.193774Z","shell.execute_reply.started":"2025-05-03T06:25:39.926840Z","shell.execute_reply":"2025-05-03T06:25:40.193230Z"}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"**2. Trying Different Models**\n\n    1. Logistic Regression\n    2. Random Forest\n    3. SVM with Linear Kernal\n    ","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nmodel1 = LogisticRegression(max_iter=1000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T06:25:42.726858Z","iopub.execute_input":"2025-05-03T06:25:42.727180Z","iopub.status.idle":"2025-05-03T06:25:42.730817Z","shell.execute_reply.started":"2025-05-03T06:25:42.727159Z","shell.execute_reply":"2025-05-03T06:25:42.730217Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"model1.fit(X_train, y_train)\nprint(model1.score(X_test, y_test))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T06:25:45.274500Z","iopub.execute_input":"2025-05-03T06:25:45.274750Z","iopub.status.idle":"2025-05-03T06:25:45.779065Z","shell.execute_reply.started":"2025-05-03T06:25:45.274733Z","shell.execute_reply":"2025-05-03T06:25:45.775477Z"}},"outputs":[{"name":"stdout","text":"0.845376263571696\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"user = input(\"Enter a Text: \")\ndata = tfidf.transform([user]).toarray()\noutput = model1.predict(data)\nprint(output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T06:28:58.209611Z","iopub.execute_input":"2025-05-03T06:28:58.210235Z","iopub.status.idle":"2025-05-03T06:29:11.649844Z","shell.execute_reply.started":"2025-05-03T06:28:58.210210Z","shell.execute_reply":"2025-05-03T06:29:11.649222Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"Enter a Text:  Cows lose their jobs as milk prices drop\n"},{"name":"stdout","text":"['Not Sarcasm']\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nmodel2 = RandomForestClassifier()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T06:29:53.067223Z","iopub.execute_input":"2025-05-03T06:29:53.067517Z","iopub.status.idle":"2025-05-03T06:29:53.071523Z","shell.execute_reply.started":"2025-05-03T06:29:53.067496Z","shell.execute_reply":"2025-05-03T06:29:53.070718Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"model2.fit(X_train, y_train)\nprint(model2.score(X_test, y_test))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T06:29:56.904050Z","iopub.execute_input":"2025-05-03T06:29:56.904726Z","iopub.status.idle":"2025-05-03T06:30:52.874390Z","shell.execute_reply.started":"2025-05-03T06:29:56.904703Z","shell.execute_reply":"2025-05-03T06:30:52.873382Z"}},"outputs":[{"name":"stdout","text":"0.8163609135155373\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"user = input(\"Enter a Text: \")\ndata = tfidf.transform([user]).toarray()\noutput = model2.predict(data)\nprint(output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T06:30:52.875750Z","iopub.execute_input":"2025-05-03T06:30:52.876034Z","iopub.status.idle":"2025-05-03T06:31:27.615242Z","shell.execute_reply.started":"2025-05-03T06:30:52.876014Z","shell.execute_reply":"2025-05-03T06:31:27.614623Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"Enter a Text:  Cows lose their jobs as milk prices drop\n"},{"name":"stdout","text":"['Not Sarcasm']\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"from sklearn.svm import LinearSVC\nmodel3 = LinearSVC()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T06:31:36.589538Z","iopub.execute_input":"2025-05-03T06:31:36.590057Z","iopub.status.idle":"2025-05-03T06:31:36.593260Z","shell.execute_reply.started":"2025-05-03T06:31:36.590029Z","shell.execute_reply":"2025-05-03T06:31:36.592683Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"model3.fit(X_train, y_train)\nprint(model3.score(X_test, y_test))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T06:31:40.048901Z","iopub.execute_input":"2025-05-03T06:31:40.049583Z","iopub.status.idle":"2025-05-03T06:31:40.152779Z","shell.execute_reply.started":"2025-05-03T06:31:40.049562Z","shell.execute_reply":"2025-05-03T06:31:40.152186Z"}},"outputs":[{"name":"stdout","text":"0.840134780980906\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"user = input(\"Enter a Text: \")\ndata = tfidf.transform([user]).toarray()\noutput = model3.predict(data)\nprint(output)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T06:31:49.833334Z","iopub.execute_input":"2025-05-03T06:31:49.833849Z","iopub.status.idle":"2025-05-03T06:32:04.436896Z","shell.execute_reply.started":"2025-05-03T06:31:49.833824Z","shell.execute_reply":"2025-05-03T06:32:04.436229Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"Enter a Text:   Cows lose their jobs as milk prices drop\n"},{"name":"stdout","text":"['Sarcasm']\n","output_type":"stream"}],"execution_count":40},{"cell_type":"markdown","source":"**NOW WE TRY TO DO WITH ENSEMBLE LEARNING**","metadata":{}},{"cell_type":"code","source":"# Import additional required libraries\nfrom sklearn.ensemble import VotingClassifier, StackingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.model_selection import cross_val_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# 1. Enhanced Ensemble Model Setup\n# Define individual models\nmodel1 = LogisticRegression(max_iter=1000, random_state=42)\nmodel2 = BernoulliNB()\nmodel3 = SVC(kernel='linear', probability=True, random_state=42)\n\n# Create voting classifier (soft voting for probability estimates)\nvoting_clf = VotingClassifier(\n    estimators=[\n        ('lr', model1),\n        ('bnb', model2),\n        ('svc', model3)\n    ],\n    voting='soft'  # Use soft voting for better probability estimates\n)\n\n# 2. Train and Evaluate the Ensemble Model\nvoting_clf.fit(X_train, y_train)\ny_pred = voting_clf.predict(X_test)\n\n# Print accuracy and detailed classification report\nprint(\"Ensemble Model Accuracy:\", voting_clf.score(X_test, y_test))\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred))\n\n\n# 4. Cross-Validation for More Reliable Evaluation\nscores = cross_val_score(voting_clf, X, y, cv=5, scoring='accuracy')\nprint(\"\\nCross-Validation Scores:\", scores)\nprint(\"Mean CV Accuracy:\", scores.mean())\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T06:39:09.883276Z","iopub.execute_input":"2025-05-03T06:39:09.883895Z","iopub.status.idle":"2025-05-03T07:06:31.772859Z","shell.execute_reply.started":"2025-05-03T06:39:09.883870Z","shell.execute_reply":"2025-05-03T07:06:31.772185Z"}},"outputs":[{"name":"stdout","text":"Ensemble Model Accuracy: 0.8538000748783228\n\nClassification Report:\n              precision    recall  f1-score   support\n\n Not Sarcasm       0.85      0.89      0.87      2996\n     Sarcasm       0.85      0.81      0.83      2346\n\n    accuracy                           0.85      5342\n   macro avg       0.85      0.85      0.85      5342\nweighted avg       0.85      0.85      0.85      5342\n\n\nCross-Validation Scores: [0.8573568  0.85754399 0.8659678  0.84930738 0.84871747]\nMean CV Accuracy: 0.8557786865394474\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}